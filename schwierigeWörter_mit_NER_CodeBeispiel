import spacy
import pandas as pd

# Lade das deutsche NER-Modell
nlp = spacy.load("de_core_news_sm")

# Funktion zum Laden des Grundwortschatzes
def load_grundwortschatz(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            words = [line.strip().lower() for line in f if line.strip()]
        return set(words)  # Set für schnelleren Vergleich
    except Exception as e:
        print(f"Fehler beim Laden der Grundwortschatz-Datei: {e}")
        return set()

# Funktion zur Erkennung schwieriger Wörter
def erkenne_schwere_wörter(text, grundwortschatz):
    # Text mit SpaCy verarbeiten
    doc = nlp(text)

    # Listen für Ergebnisse
    grundwörter = []
    schwierige_wörter = []

    # Wörter prüfen
    for token in doc:
        if token.is_alpha:  # Nur Wörter, keine Satzzeichen
            wort = token.text.lower()
            if wort in grundwortschatz:
                grundwörter.append(wort)
            else:
                schwierige_wörter.append(wort)

    return grundwörter, schwierige_wörter

# Funktion zur Verarbeitung des hochgeladenen Datasets
def verarbeite_dataset(file_path, grundwortschatz_path):
    # Lade den Grundwortschatz
    grundwortschatz = load_grundwortschatz(grundwortschatz_path)

    # Lade die hochgeladenen Texte
    try:
        if file_path.endswith(".txt"):
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()
        elif file_path.endswith(".csv"):
            df = pd.read_csv(file_path)
            text = " ".join(df.iloc[:, 0].astype(str))  # Annahme: Text ist in der ersten Spalte
        elif file_path.endswith(".json"):
            df = pd.read_json(file_path)
            text = " ".join(df.iloc[:, 0].astype(str))
        else:
            raise ValueError("Nur .txt, .csv oder .json Dateien werden unterstützt.")
    except Exception as e:
        return f"Fehler beim Laden der Datei: {e}"

    # Schwierige Wörter erkennen
    grundwörter, schwierige_wörter = erkenne_schwere_wörter(text, grundwortschatz)
    return grundwörter, schwierige_wörter

# Hauptprogramm
if __name__ == "__main__":
    # Beispielpfade
    dataset_path = "kindertexte.txt"  # Muss ich noch durch tatsächlichen Pfad erstezten
    grundwortschatz_path = "grundwortschatz.txt"

    # Verarbeite das Dataset
    ergebnisse = verarbeite_dataset(dataset_path, grundwortschatz_path)

    if isinstance(ergebnisse, tuple):  # Wenn keine Fehler auftraten
        grundwörter, schwierige_wörter = ergebnisse
        print("Grundwörter:", grundwörter)
        print("Schwierige Wörter:", schwierige_wörter)
    else:
        print(ergebnisse)  # Fehlernachricht ausgeben
